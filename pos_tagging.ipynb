{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MWO2aP7ZEkYB"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q63sEoKEs0Q",
        "outputId": "4078fd37-7092-4e07-f9fa-efb91eb15f1b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "paragraph =\"\"\" Human language is filled with ambiguities that make it incredibly difficult to write software that accurately determines the intended meaning of text or voice data. Homonyms, homophones, sarcasm, idioms, metaphors,\n",
        "grammar and usage exceptions, variations in sentence structure these just a few of the irregularities of human language that\n",
        "take humans years to learn, but that programmers must teach natural language-driven applications to recognize and understand\n",
        "accurately from the start, if those applications are going to be useful.\"\"\""
      ],
      "metadata": {
        "id": "W4y5644lEsx0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "oKg15349Esvn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDvx8JoOEstG",
        "outputId": "5d9311a5-9dda-4d12-ede7-ec5482ad9caa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' Human language is filled with ambiguities that make it incredibly difficult to write software that accurately determines the intended meaning of text or voice data.',\n",
              " 'Homonyms, homophones, sarcasm, idioms, metaphors,\\ngrammar and usage exceptions, variations in sentence structure these just a few of the irregularities of human language that\\ntake humans years to learn, but that programmers must teach natural language-driven applications to recognize and understand \\naccurately from the start, if those applications are going to be useful.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = nltk.word_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "VjgFpZakEsq0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ally8D5HEsoa",
        "outputId": "c4019868-a450-47f2-b8e8-ccb2458edde6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Human',\n",
              " 'language',\n",
              " 'is',\n",
              " 'filled',\n",
              " 'with',\n",
              " 'ambiguities',\n",
              " 'that',\n",
              " 'make',\n",
              " 'it',\n",
              " 'incredibly',\n",
              " 'difficult',\n",
              " 'to',\n",
              " 'write',\n",
              " 'software',\n",
              " 'that',\n",
              " 'accurately',\n",
              " 'determines',\n",
              " 'the',\n",
              " 'intended',\n",
              " 'meaning',\n",
              " 'of',\n",
              " 'text',\n",
              " 'or',\n",
              " 'voice',\n",
              " 'data',\n",
              " '.',\n",
              " 'Homonyms',\n",
              " ',',\n",
              " 'homophones',\n",
              " ',',\n",
              " 'sarcasm',\n",
              " ',',\n",
              " 'idioms',\n",
              " ',',\n",
              " 'metaphors',\n",
              " ',',\n",
              " 'grammar',\n",
              " 'and',\n",
              " 'usage',\n",
              " 'exceptions',\n",
              " ',',\n",
              " 'variations',\n",
              " 'in',\n",
              " 'sentence',\n",
              " 'structure',\n",
              " 'these',\n",
              " 'just',\n",
              " 'a',\n",
              " 'few',\n",
              " 'of',\n",
              " 'the',\n",
              " 'irregularities',\n",
              " 'of',\n",
              " 'human',\n",
              " 'language',\n",
              " 'that',\n",
              " 'take',\n",
              " 'humans',\n",
              " 'years',\n",
              " 'to',\n",
              " 'learn',\n",
              " ',',\n",
              " 'but',\n",
              " 'that',\n",
              " 'programmers',\n",
              " 'must',\n",
              " 'teach',\n",
              " 'natural',\n",
              " 'language-driven',\n",
              " 'applications',\n",
              " 'to',\n",
              " 'recognize',\n",
              " 'and',\n",
              " 'understand',\n",
              " 'accurately',\n",
              " 'from',\n",
              " 'the',\n",
              " 'start',\n",
              " ',',\n",
              " 'if',\n",
              " 'those',\n",
              " 'applications',\n",
              " 'are',\n",
              " 'going',\n",
              " 'to',\n",
              " 'be',\n",
              " 'useful',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming"
      ],
      "metadata": {
        "id": "lsfSruF6FD3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer"
      ],
      "metadata": {
        "id": "lpvaRNFSEsmI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9gCdATeBEsjw",
        "outputId": "492892e8-19b8-4b50-e0b3-a3da55c61936"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "P9GsbXeREsgs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.fileids()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spj4x6P5FPDE",
        "outputId": "334b60e3-18b7-49fd-b869-17d26a9d46aa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['arabic',\n",
              " 'azerbaijani',\n",
              " 'basque',\n",
              " 'bengali',\n",
              " 'catalan',\n",
              " 'chinese',\n",
              " 'danish',\n",
              " 'dutch',\n",
              " 'english',\n",
              " 'finnish',\n",
              " 'french',\n",
              " 'german',\n",
              " 'greek',\n",
              " 'hebrew',\n",
              " 'hinglish',\n",
              " 'hungarian',\n",
              " 'indonesian',\n",
              " 'italian',\n",
              " 'kazakh',\n",
              " 'nepali',\n",
              " 'norwegian',\n",
              " 'portuguese',\n",
              " 'romanian',\n",
              " 'russian',\n",
              " 'slovene',\n",
              " 'spanish',\n",
              " 'swedish',\n",
              " 'tajik',\n",
              " 'turkish']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "iEvu7mr-FO_l"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentences[i] = ' '.join(words)"
      ],
      "metadata": {
        "id": "4PFtDykqFO9h"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vYMN9hyFO7M",
        "outputId": "8dfeead1-90d5-4fcc-8d65-c807fa07696f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['homonym',\n",
              " ',',\n",
              " 'homophon',\n",
              " ',',\n",
              " 'sarcasm',\n",
              " ',',\n",
              " 'idiom',\n",
              " ',',\n",
              " 'metaphor',\n",
              " ',',\n",
              " 'grammar',\n",
              " 'usag',\n",
              " 'except',\n",
              " ',',\n",
              " 'variat',\n",
              " 'sentenc',\n",
              " 'structur',\n",
              " 'irregular',\n",
              " 'human',\n",
              " 'languag',\n",
              " 'take',\n",
              " 'human',\n",
              " 'year',\n",
              " 'learn',\n",
              " ',',\n",
              " 'programm',\n",
              " 'must',\n",
              " 'teach',\n",
              " 'natur',\n",
              " 'language-driven',\n",
              " 'applic',\n",
              " 'recogn',\n",
              " 'understand',\n",
              " 'accur',\n",
              " 'start',\n",
              " ',',\n",
              " 'applic',\n",
              " 'go',\n",
              " 'use',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "84LS8wrBFauD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "metadata": {
        "id": "hjqeCJLMFO3l"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords"
      ],
      "metadata": {
        "id": "Zq4hW7hhFO0H"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = nltk.sent_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "31MmNcEGFOxo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "hWPBo0M_FOvo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egm1OiBVFkel",
        "outputId": "03680403-8895-420f-9f3c-d8ceb7bee101"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(sentences)):\n",
        "  words = nltk.word_tokenize(sentences[i])\n",
        "  words = [lemmatizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  sentences[i] = ' ' .join(words)"
      ],
      "metadata": {
        "id": "QqxMv0q_FkbF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHwb-onGFkYs",
        "outputId": "743fde06-f498-4c2e-debd-dafe0b65c9b2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Homonyms',\n",
              " ',',\n",
              " 'homophone',\n",
              " ',',\n",
              " 'sarcasm',\n",
              " ',',\n",
              " 'idiom',\n",
              " ',',\n",
              " 'metaphor',\n",
              " ',',\n",
              " 'grammar',\n",
              " 'usage',\n",
              " 'exception',\n",
              " ',',\n",
              " 'variation',\n",
              " 'sentence',\n",
              " 'structure',\n",
              " 'irregularity',\n",
              " 'human',\n",
              " 'language',\n",
              " 'take',\n",
              " 'human',\n",
              " 'year',\n",
              " 'learn',\n",
              " ',',\n",
              " 'programmer',\n",
              " 'must',\n",
              " 'teach',\n",
              " 'natural',\n",
              " 'language-driven',\n",
              " 'application',\n",
              " 'recognize',\n",
              " 'understand',\n",
              " 'accurately',\n",
              " 'start',\n",
              " ',',\n",
              " 'application',\n",
              " 'going',\n",
              " 'useful',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenizer = nltk.word_tokenize(paragraph)"
      ],
      "metadata": {
        "id": "uA4658TAFkV7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU1X7-_EFkTi",
        "outputId": "20c2a34b-867d-4160-c5d0-e639643cd19d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos = nltk.pos_tag(word_tokenizer)"
      ],
      "metadata": {
        "id": "ES57y1BDFkRQ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gt9Kz17FkO3",
        "outputId": "8b34c6d1-b543-414f-ea80-7f1f3390e863"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Human', 'JJ'),\n",
              " ('language', 'NN'),\n",
              " ('is', 'VBZ'),\n",
              " ('filled', 'VBN'),\n",
              " ('with', 'IN'),\n",
              " ('ambiguities', 'NNS'),\n",
              " ('that', 'WDT'),\n",
              " ('make', 'VBP'),\n",
              " ('it', 'PRP'),\n",
              " ('incredibly', 'RB'),\n",
              " ('difficult', 'JJ'),\n",
              " ('to', 'TO'),\n",
              " ('write', 'VB'),\n",
              " ('software', 'NN'),\n",
              " ('that', 'WDT'),\n",
              " ('accurately', 'RB'),\n",
              " ('determines', 'VBZ'),\n",
              " ('the', 'DT'),\n",
              " ('intended', 'JJ'),\n",
              " ('meaning', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('text', 'NN'),\n",
              " ('or', 'CC'),\n",
              " ('voice', 'NN'),\n",
              " ('data', 'NNS'),\n",
              " ('.', '.'),\n",
              " ('Homonyms', 'NNP'),\n",
              " (',', ','),\n",
              " ('homophones', 'NNS'),\n",
              " (',', ','),\n",
              " ('sarcasm', 'NN'),\n",
              " (',', ','),\n",
              " ('idioms', 'NNS'),\n",
              " (',', ','),\n",
              " ('metaphors', 'NNS'),\n",
              " (',', ','),\n",
              " ('grammar', 'NN'),\n",
              " ('and', 'CC'),\n",
              " ('usage', 'JJ'),\n",
              " ('exceptions', 'NNS'),\n",
              " (',', ','),\n",
              " ('variations', 'NNS'),\n",
              " ('in', 'IN'),\n",
              " ('sentence', 'NN'),\n",
              " ('structure', 'NN'),\n",
              " ('these', 'DT'),\n",
              " ('just', 'RB'),\n",
              " ('a', 'DT'),\n",
              " ('few', 'JJ'),\n",
              " ('of', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('irregularities', 'NNS'),\n",
              " ('of', 'IN'),\n",
              " ('human', 'JJ'),\n",
              " ('language', 'NN'),\n",
              " ('that', 'WDT'),\n",
              " ('take', 'VBP'),\n",
              " ('humans', 'NNS'),\n",
              " ('years', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('learn', 'VB'),\n",
              " (',', ','),\n",
              " ('but', 'CC'),\n",
              " ('that', 'IN'),\n",
              " ('programmers', 'NNS'),\n",
              " ('must', 'MD'),\n",
              " ('teach', 'VB'),\n",
              " ('natural', 'JJ'),\n",
              " ('language-driven', 'JJ'),\n",
              " ('applications', 'NNS'),\n",
              " ('to', 'TO'),\n",
              " ('recognize', 'VB'),\n",
              " ('and', 'CC'),\n",
              " ('understand', 'VB'),\n",
              " ('accurately', 'RB'),\n",
              " ('from', 'IN'),\n",
              " ('the', 'DT'),\n",
              " ('start', 'NN'),\n",
              " (',', ','),\n",
              " ('if', 'IN'),\n",
              " ('those', 'DT'),\n",
              " ('applications', 'NNS'),\n",
              " ('are', 'VBP'),\n",
              " ('going', 'VBG'),\n",
              " ('to', 'TO'),\n",
              " ('be', 'VB'),\n",
              " ('useful', 'JJ'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(pos)):\n",
        "  if(pos[i][1]=='NNS'):\n",
        "    print(pos[i][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xNMrjSMF5-0",
        "outputId": "047cab40-8714-4120-eb1e-9fd7127a2369"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ambiguities\n",
            "data\n",
            "homophones\n",
            "idioms\n",
            "metaphors\n",
            "exceptions\n",
            "variations\n",
            "irregularities\n",
            "humans\n",
            "years\n",
            "programmers\n",
            "applications\n",
            "applications\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('tagsets')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ29VY1YF57b",
        "outputId": "2f336daa-06d9-44f0-a42c-6f60ac4704f9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.help.upenn_tagset('VBG')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQCG__ySF542",
        "outputId": "a2646267-c9ce-4858-e684-e55faee319fd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VBG: verb, present participle or gerund\n",
            "    telegraphing stirring focusing angering judging stalling lactating\n",
            "    hankerin' alleging veering capping approaching traveling besieging\n",
            "    encrypting interrupting erasing wincing ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bCdD43MMF52g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ekOOl7FPF50Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}